{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import json\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ta feng\n",
    "import csv\n",
    "\n",
    "def extract_csv(file_names):\n",
    "    for f in file_names:\n",
    "        with open(f, 'rt') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for i, line in enumerate(reader):\n",
    "                if(i == 0):\n",
    "                    continue\n",
    "                yield line\n",
    "\n",
    "rdd = sc.parallelize(['./ta_feng_all_months_merged.csv']).mapPartitions(extract_csv)\n",
    "header = rdd.first()\n",
    "\n",
    "rdd = rdd.map(lambda x: '{}-{},{}'.format(x[0], x[1], int(x[5]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"preprocessed_data.csv\", \"wt\") as f:\n",
    "    f.write(\"DATE-CUSTOMER_ID,PRODUCT_ID\\n\")\n",
    "    for i, l in enumerate(rdd):    \n",
    "        f.write(l+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_rdd = reading_baskets('preprocessed_data.csv', 1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('11/1/2000-01849332',\n",
       "  ['4710126031890',\n",
       "   '4710085120628',\n",
       "   '4710304111147',\n",
       "   '4710857000011',\n",
       "   '4711524000433',\n",
       "   '4714981010038',\n",
       "   '9310034370095',\n",
       "   '4710085172696',\n",
       "   '4713608210912',\n",
       "   '7610700600863',\n",
       "   '4711524000907',\n",
       "   '4901201101021',\n",
       "   '4710011405133',\n",
       "   '4710047502011',\n",
       "   '4710199010778',\n",
       "   '9310135026372',\n",
       "   '4711524000891',\n",
       "   '4710011409056',\n",
       "   '4710011406123',\n",
       "   '4903065141502',\n",
       "   '4719862260427',\n",
       "   '4710047512515',\n",
       "   '4710011432832',\n",
       "   '4711524001041',\n",
       "   '4710098166811',\n",
       "   '89782012029',\n",
       "   '4710126092105',\n",
       "   '4710126092129']),\n",
       " ('11/1/2000-02154039',\n",
       "  ['4719090900058',\n",
       "   '4710085120628',\n",
       "   '4710144101452',\n",
       "   '4710199010174',\n",
       "   '4710265849066',\n",
       "   '4710085120093',\n",
       "   '4710583110015',\n",
       "   '20415723',\n",
       "   '4710247005831',\n",
       "   '4710105026411',\n",
       "   '4710088410139',\n",
       "   '4710085172696',\n",
       "   '723125481409',\n",
       "   '4710254031342',\n",
       "   '4710011401128',\n",
       "   '4711080010112',\n",
       "   '4710670200407',\n",
       "   '4710088414052',\n",
       "   '4710670200100',\n",
       "   '4710011405133',\n",
       "   '4711437000131',\n",
       "   '4710861100011',\n",
       "   '4710626521716',\n",
       "   '4903035300380',\n",
       "   '4710011409056',\n",
       "   '4710126020283',\n",
       "   '28400017305',\n",
       "   '4710191030002',\n",
       "   '4710105020327',\n",
       "   '4710088410382',\n",
       "   '4710011401135',\n",
       "   '4711300986982',\n",
       "   '4902556125205',\n",
       "   '4710323168054',\n",
       "   '4710063131493'])]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets_rdd.collect()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_line(line):\n",
    "    line = line.split(',')\n",
    "    return (line[0].strip(), line[1].strip())\n",
    "\n",
    "def reading_baskets(input_file_path, case_number):\n",
    "    rdd = sc.textFile(input_file_path)\n",
    "    header = rdd.first()\n",
    "    \n",
    "    if(case_number == 1):\n",
    "        rdd = rdd.filter(lambda x: x != header).map(read_csv_line).groupByKey().map(lambda x : (x[0], list(set(x[1]))))\n",
    "    else:\n",
    "        rdd = rdd.filter(lambda x: x != header).map(read_csv_line).map(lambda x: (x[1], x[0])).groupByKey().map(lambda x : (x[0], list(set(x[1]))))\n",
    "    return rdd\n",
    "\n",
    "# def gen_candidates(baskets, frequent_items, k):\n",
    "#     candidates = []\n",
    "#     if(k == 1):\n",
    "#         for _, b in baskets:\n",
    "#             for c in itertools.combinations(b, k):\n",
    "#                 candidates.append(frozenset(c))\n",
    "                \n",
    "#         return list(set(candidates))\n",
    "    \n",
    "#     for _, b in baskets:\n",
    "#         for c in itertools.combinations(b, k):\n",
    "#             sub_combinations = set(frozenset(x) for x in itertools.combinations(c, k-1))\n",
    "#             if(sub_combinations.issubset(set(frequent_items))):\n",
    "#                 candidates.append(frozenset(c))\n",
    "                \n",
    "#     return list(set(candidates))\n",
    "\n",
    "def gen_candidates(baskets, frequent_items, k):\n",
    "    candidates = []\n",
    "    if(k == 1):\n",
    "        for _, b in baskets:\n",
    "            for c in itertools.combinations(b, k):\n",
    "                candidates.append(frozenset(c))\n",
    "                \n",
    "        return list(set(candidates))\n",
    "    \n",
    "#     for _, b in baskets:\n",
    "#         for c in itertools.combinations(b, k):\n",
    "    for s1, s2 in itertools.combinations(frequent_items, 2):\n",
    "        c = s1.union(s2)\n",
    "        if(len(c) == k):\n",
    "            candidates.append(frozenset(c))\n",
    "            \n",
    "    return list(set(candidates))\n",
    "    \n",
    "    \n",
    "def calculate_support(baskets, candidate):\n",
    "    count = 0\n",
    "#     k = len(candidate)\n",
    "    candidate = set(candidate)\n",
    "    for _, b in baskets:\n",
    "        b = set(b)\n",
    "#         combinations = set(frozenset(x) for x in itertools.combinations(b, k))\n",
    "        if(candidate.issubset(b)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# def calculate_support(baskets, k):\n",
    "#     counter = {}\n",
    "#     for _, b in baskets:\n",
    "# #         b = list(b)\n",
    "#         combinations = [frozenset(x) for x in itertools.combinations(b, k)]\n",
    "#         for c in combinations:\n",
    "#             if(c in counter):\n",
    "#                 counter[c] += 1\n",
    "#             else:\n",
    "#                 counter[c] = 1\n",
    "#     return counter\n",
    "\n",
    "\n",
    "def apriori(baskets, sup):\n",
    "    k = 1\n",
    "    candidates = gen_candidates(baskets, [], 1)\n",
    "    output = []\n",
    "    while(len(candidates) != 0):\n",
    "        frequent_items = []\n",
    "        for c in candidates:\n",
    "            if(calculate_support(baskets, c) >= sup):\n",
    "                frequent_items.append(c)\n",
    "        \n",
    "#         output['candidate'][k] = candidates\n",
    "        output += frequent_items\n",
    "        k += 1\n",
    "        candidates = gen_candidates(baskets, frequent_items, k)\n",
    "        \n",
    "    return list(set(output))\n",
    "\n",
    "\n",
    "\n",
    "def apriori_son(baskets_iterator, sup, total_len):\n",
    "    baskets = []\n",
    "    len_partition = 0\n",
    "    for b in baskets_iterator:\n",
    "        baskets.append(b)\n",
    "        len_partition += 1\n",
    "        \n",
    "    partition_sup = math.ceil(sup * len_partition / total_len)\n",
    "#     yield (partition_sup, len_partition, total_len)\n",
    "    result = apriori(baskets, partition_sup)\n",
    "    for x in result:\n",
    "        yield x\n",
    "\n",
    "    \n",
    "def phase2_count(basket_iterator, candidates):\n",
    "    baskets = [x for x in basket_iterator]\n",
    "    for c in candidates:\n",
    "        yield (c, calculate_support(baskets, c))\n",
    "        \n",
    "        \n",
    "def prepare_output(candidates, frequent):\n",
    "    output_candidate = {}\n",
    "    for item in candidates:\n",
    "        item = tuple(sorted(tuple(item)))\n",
    "        if(len(item) in output_candidate):\n",
    "            output_candidate[len(item)].append(item)\n",
    "        else:\n",
    "            output_candidate[len(item)] = [item]\n",
    "    \n",
    "    output_frequent = {}\n",
    "    for item, _ in frequent:\n",
    "        item = tuple(sorted(tuple(item)))\n",
    "        if(len(item) in output_frequent):\n",
    "            output_frequent[len(item)].append(item)\n",
    "        else:\n",
    "            output_frequent[len(item)] = [item]\n",
    "            \n",
    "    for k, v in output_candidate.items():\n",
    "        output_candidate[k] = sorted(v)\n",
    "        \n",
    "    for k, v in output_frequent.items():\n",
    "        output_frequent[k] = sorted(v)\n",
    "        \n",
    "        \n",
    "    for k, v in output_candidate.items():\n",
    "        if(k == 1):\n",
    "            output_candidate[k] = \",\".join([\"({})\".format(x[0]) for x in v])\n",
    "            continue\n",
    "        output_candidate[k] = \",\".join([str(x) for x in v])\n",
    "        \n",
    "        \n",
    "    for k, v in output_frequent.items():\n",
    "        if(k == 1):\n",
    "            output_frequent[k] = \",\".join([\"({})\".format(x[0]) for x in v])\n",
    "            continue\n",
    "        output_frequent[k] = \",\".join([str(x) for x in v])\n",
    "    \n",
    "            \n",
    "    return output_candidate, output_frequent\n",
    "\n",
    "\n",
    "def save_output(output_candidate, output_frequent, output_path):\n",
    "    with open(output_path, 'wt') as file:\n",
    "        file.write(\"Candidates:\\n\")\n",
    "        for k in sorted(output_candidate.keys()):\n",
    "            file.write(output_candidate[k]+'\\n')\n",
    "            file.write('\\n')\n",
    "        file.write(\"Frequent Itemsets:\\n\")\n",
    "        for k in sorted(output_frequent.keys()):\n",
    "            file.write(output_frequent[k]+'\\n')\n",
    "            file.write('\\n')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appName = 'assignment2'\n",
    "# master = 'local[*]'\n",
    "# conf = SparkConf().setAppName(appName).setMaster(master)\n",
    "config = SparkConf().setAll([('spark.executor.memory', '8g'), ('spark.executor.cores', '3'), ('spark.cores.max', '3'), ('spark.driver.memory','8g')])\n",
    "sc = SparkContext(conf=config)\n",
    "# sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "baskets_rdd = reading_baskets('small1.csv', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o = apriori(baskets_rdd.collect(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_candidate = {}\n",
    "# for item in o:\n",
    "#     item = tuple(sorted(tuple(item)))\n",
    "#     if(len(item) in output_candidate):\n",
    "#         output_candidate[len(item)].append(item)\n",
    "#     else:\n",
    "#         output_candidate[len(item)] = [item]\n",
    "        \n",
    "# for k, v in output_candidate.items():\n",
    "#     output_candidate[k] = sorted(v)\n",
    "\n",
    "# for k, v in output_candidate.items():\n",
    "#     output_candidate[k] = \",\".join([str(x) for x in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5652 16\n"
     ]
    }
   ],
   "source": [
    "def reading_baskets(input_file_path, case_number, filter_thresh):\n",
    "    rdd = sc.textFile(input_file_path)\n",
    "    header = rdd.first()\n",
    "    \n",
    "    if(case_number == 1):\n",
    "        rdd = rdd.filter(lambda x: x != header).map(read_csv_line).groupByKey().filter(lambda x: len(x[1]) > 20).map(lambda x : (x[0], list(set(x[1]))))\n",
    "    else:\n",
    "        rdd = rdd.filter(lambda x: x != header).map(read_csv_line).map(lambda x: (x[1], x[0])).groupByKey().filter(lambda x: len(x[1]) > 20).map(lambda x : (x[0], list(set(x[1]))))\n",
    "    return rdd\n",
    "\n",
    "support = 50\n",
    "filter_threshold = 20\n",
    "baskets_rdd = reading_baskets(\"preprocessed_data.csv\", 1, filter_threshold)\n",
    "baskets_rdd = baskets_rdd.repartition(16)\n",
    "total_len = baskets_rdd.count()\n",
    "print(total_len, baskets_rdd.getNumPartitions())\n",
    "phase1 = baskets_rdd.mapPartitions(lambda x: apriori_son(x, support, total_len))\n",
    "candidates = list(set(phase1.collect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase2 = baskets_rdd.mapPartitions(lambda x: phase2_count(x, candidates)).reduceByKey(lambda a, b: a+b).filter(lambda x: x[1] >= support)\n",
    "frequent = phase2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "o_c, o_f = prepare_output(candidates, frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: \"('100', '101'),('100', '98'),('101', '102'),('101', '97'),('101', '98'),('101', '99'),('102', '103'),('102', '97'),('102', '98'),('102', '99'),('103', '99'),('97', '98'),('97', '99'),('98', '99')\",\n",
       " 1: '(100),(101),(102),(103),(97),(98),(99)',\n",
       " 3: \"('100', '101', '98'),('101', '97', '99'),('102', '103', '99'),('97', '98', '99')\"}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_output(o_c, o_f, 'output2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [frozenset(x) for x in itertools.combinations(range(0, 10), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0].union(a[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
